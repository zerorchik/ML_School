# -*- coding: utf-8 -*-
"""Rock_paper_scissors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13g8zBP1S8aVOhAFTC5oVULaWhG0J96Qj

# Бібліотеки
"""

import tensorflow as tf
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Conv2D, MaxPooling2D
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import seaborn as sn
import pandas as pd
import numpy as np
from keras.utils.np_utils import to_categorical

"""# Гіперпараметри"""

BATCH_SIZE = 64
EPOCHS = 20
LEARNING_RATE = 0.001

"""# Підготовка датасетів"""

(train_data, val_data, test_data), metadata = tfds.load('rock_paper_scissors', split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'], with_info=True)
print(metadata.features)

tfds.visualization.show_examples(train_data, metadata)

def preprocess(dataset):
    image = tf.cast(dataset['image'], dtype=tf.float32) / 255.
    label = tf.cast(dataset['label'], dtype=tf.float32)
    return image, label


train_data = train_data.map(preprocess).shuffle(buffer_size=1024).batch(BATCH_SIZE)
val_data = val_data.map(preprocess).batch(BATCH_SIZE)
test_data = test_data.map(preprocess).batch(BATCH_SIZE)

"""# Модель"""

def simple_mlp_model(num_classes):
    input_ = tf.keras.layers.Input(shape=(300, 300, 3,))
    x = tf.keras.layers.Flatten()(input_)
    x = tf.keras.layers.Dense(128, activation='relu')(x)
    x = tf.keras.layers.Dense(128, activation='relu')(x)
    x = tf.keras.layers.Dense(64, activation='relu')(x)
    x = tf.keras.layers.Dense(64, activation='relu')(x)
    output_ = tf.keras.layers.Dense(num_classes, activation='softmax')(x)
    return tf.keras.models.Model(input_, output_, name='Classifier')

num_classes = metadata.features['label'].num_classes
model = simple_mlp_model(num_classes)
model.summary()

"""# Компіляція"""

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(LEARNING_RATE,
                                                             decay_steps=100000,
                                                             decay_rate=0.96)

model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule),
              loss = tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics = ['accuracy'])

"""# Тренування"""

history = model.fit(train_data, epochs=EPOCHS, validation_data=val_data)

"""# Результат"""

metrics = model.evaluate(test_data, batch_size=BATCH_SIZE, verbose=1)
metric_names = ['Test loss', 'Test Accuracy']

for name, value in zip(metric_names, metrics):
    print(f'{name} : {value}')

"""# Графік точності"""

plt.plot(history.history['accuracy'], label = 'Train accuracy')
plt.plot(history.history['val_accuracy'], label = 'Val accuracy')
plt.title('Train and test accuracy')
plt.legend()
plt.figure(figsize = (100,100))
plt.show()